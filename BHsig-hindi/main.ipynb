{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2fa897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:49.852848Z",
     "iopub.status.busy": "2024-07-21T11:49:49.851896Z",
     "iopub.status.idle": "2024-07-21T11:49:55.788775Z",
     "shell.execute_reply": "2024-07-21T11:49:55.787822Z"
    },
    "papermill": {
     "duration": 5.946398,
     "end_time": "2024-07-21T11:49:55.791067",
     "exception": false,
     "start_time": "2024-07-21T11:49:49.844669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93ad317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.803588Z",
     "iopub.status.busy": "2024-07-21T11:49:55.802544Z",
     "iopub.status.idle": "2024-07-21T11:49:55.815378Z",
     "shell.execute_reply": "2024-07-21T11:49:55.814700Z"
    },
    "papermill": {
     "duration": 0.020651,
     "end_time": "2024-07-21T11:49:55.817241",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.796590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SigDataset_train(Dataset):\n",
    "\n",
    "    def __init__(self , path,transforms=None):\n",
    "\n",
    "        \n",
    "\n",
    "        self.path = path\n",
    "        \n",
    "        self.transform=transforms\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self , idx):\n",
    "        person_id = int(idx % 128) + 1 #since total number of authors are 160 and i am using 1- 128 for training\n",
    "        sample = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))# for Randomly picking a signature\n",
    "              \n",
    "        org_img_name = 'H-S-'+ str(person_id) + '-G-' + sample + '.tif' #original signature image name\n",
    "        org_img_path = os.path.join(self.path , str(person_id),org_img_name)\n",
    "        org_img = Image.open(org_img_path).convert('L') # Inputing the image using PIL and converting it to grey scale\n",
    "        img0=ImageOps.invert(org_img)#inverting the image so that signature of white in colour on a black background\n",
    "        \n",
    "\n",
    "\n",
    "        label = int(np.random.randint(low = 0 , high = 2 , size = 1)) # selecting the second image.\n",
    "                                                                      # if 0 pick one original image.\n",
    "                                                                      # if 1 pick a forged image.\n",
    "\n",
    "\n",
    "\n",
    "        if label == 1:\n",
    "            # Picking forged image #\n",
    "            sample1 = str(int(np.random.randint(low = 1 , high = 31 , size = 1)))\n",
    "            forg_img_name = 'H-S-'+ str(person_id) + '-F-' + sample1 + '.tif'\n",
    "            forg_img_path = os.path.join(self.path ,str(person_id) ,forg_img_name)\n",
    "            forg_img = Image.open(forg_img_path).convert('L')\n",
    "            img1 = ImageOps.invert(forg_img)\n",
    "\n",
    "        else:\n",
    "            # Picking real image #\n",
    "            sample2 = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))\n",
    "            sim_img_name = 'H-S-'+ str(person_id) + '-G-' + sample2 + '.tif'\n",
    "            sim_img_path = os.path.join(self.path ,str(person_id) ,sim_img_name)\n",
    "            sim_img = Image.open(sim_img_path).convert('L')\n",
    "            img1 = ImageOps.invert(sim_img)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img0=self.transform(img0)#will be used to resize the image and convert it into tensor\n",
    "            img1=self.transform(img1)\n",
    "        return img0,img1,torch.from_numpy(np.array([int(label)],dtype=np.float32))\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        # since there are 128 authors and each have 24 original signature\n",
    "\n",
    "        return 128*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194ecff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.828150Z",
     "iopub.status.busy": "2024-07-21T11:49:55.827897Z",
     "iopub.status.idle": "2024-07-21T11:49:55.839975Z",
     "shell.execute_reply": "2024-07-21T11:49:55.839123Z"
    },
    "papermill": {
     "duration": 0.01971,
     "end_time": "2024-07-21T11:49:55.841859",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.822149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SigDataset_test(Dataset):\n",
    "\n",
    "    def __init__(self , path,transforms=None):\n",
    "\n",
    "        # Setting the original and forge paths #\n",
    "\n",
    "        self.path = path\n",
    "        \n",
    "        self.transform=transforms\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self , idx):\n",
    "        person_id = int(idx % 32) + 129 #since total number of authors are 160 of which 129-160 we are using for testing\n",
    "        sample = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))# for Randomly picking a signature\n",
    "              \n",
    "        org_img_name = 'H-S-'+ str(person_id) + '-G-' + sample + '.tif' #original signature image name\n",
    "        org_img_path = os.path.join(self.path , str(person_id),org_img_name)\n",
    "        org_img = Image.open(org_img_path).convert('L') # Inputing the image using PIL and converting it to grey scale\n",
    "        img0=ImageOps.invert(org_img)#inverting the image so that signature of white in colour on a black background\n",
    "        \n",
    "\n",
    "         # selecting the second image.\n",
    "        label = int(np.random.randint(low = 0 , high = 2 , size = 1))\n",
    "                                                                      # if 0 pick one original image.\n",
    "                                                                      # if 1 pick a forged image.\n",
    "\n",
    "\n",
    "\n",
    "        if label == 1:\n",
    "            # Picking forged image #\n",
    "            sample1 = str(int(np.random.randint(low = 1 , high = 31 , size = 1)))\n",
    "            forg_img_name = 'H-S-'+ str(person_id) + '-F-' + sample1 + '.tif'\n",
    "            forg_img_path = os.path.join(self.path ,str(person_id) ,forg_img_name)\n",
    "            forg_img = Image.open(forg_img_path).convert('L')\n",
    "            img1 = ImageOps.invert(forg_img)\n",
    "\n",
    "        else:\n",
    "            # Picking real image #\n",
    "            sample2 = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))\n",
    "            sim_img_name = 'H-S-'+ str(person_id) + '-G-' + sample2 + '.tif'\n",
    "            sim_img_path = os.path.join(self.path ,str(person_id) ,sim_img_name)\n",
    "            sim_img = Image.open(sim_img_path).convert('L')\n",
    "            img1 = ImageOps.invert(sim_img)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img0=self.transform(img0)\n",
    "            img1=self.transform(img1)\n",
    "        return img0,img1,torch.from_numpy(np.array([int(label)],dtype=np.float32))\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        # since there are 32 authors in out test set and each ahs 24 original signature \n",
    "\n",
    "        return 32*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46dde97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.853661Z",
     "iopub.status.busy": "2024-07-21T11:49:55.853374Z",
     "iopub.status.idle": "2024-07-21T11:49:55.857922Z",
     "shell.execute_reply": "2024-07-21T11:49:55.857069Z"
    },
    "papermill": {
     "duration": 0.012465,
     "end_time": "2024-07-21T11:49:55.859767",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.847302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the train dataset from raw image folders\n",
    "train_dataset=SigDataset_train(r\"/kaggle/input/bhsig260-hindi/BHSig260-Hindi\",\n",
    "                               transforms=transforms.Compose([transforms.Resize((300,300)),transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6eea823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.880105Z",
     "iopub.status.busy": "2024-07-21T11:49:55.879810Z",
     "iopub.status.idle": "2024-07-21T11:49:55.901428Z",
     "shell.execute_reply": "2024-07-21T11:49:55.900508Z"
    },
    "papermill": {
     "duration": 0.029547,
     "end_time": "2024-07-21T11:49:55.903405",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.873858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the model architecture\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=9, stride=1, padding=4),  \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=2), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1),   \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 \n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1),   \n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
    "            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1),    \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1),   \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=2),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.Upsample(scale_factor=1.045, mode='bicubic')  #to mkae the image dimention 300x300\n",
    "        )\n",
    "        self.Sim1=nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1296,324),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(324,256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256,128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128,64),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x,y):\n",
    "        # x is the first image and y is the image it is compared to\n",
    "        x = self.encoder(x)\n",
    "        encoding_x=self.Sim1(self.flatten(x))\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        y = self.encoder(y)\n",
    "        encoding_y=self.Sim1(self.flatten(y))\n",
    "        y = self.decoder(y)\n",
    "        \n",
    "        return x,y,encoding_x,encoding_y\n",
    "\n",
    "\n",
    "class SimNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimNet, self).__init__()\n",
    "        \n",
    "        self.Simaese=nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64,32),\n",
    "            nn.Linear(32,16),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(16,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x_encoding,y_encoding):\n",
    "        diff=x_encoding-y_encoding\n",
    "        out=self.Simaese(diff)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effb2051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.914949Z",
     "iopub.status.busy": "2024-07-21T11:49:55.914583Z",
     "iopub.status.idle": "2024-07-21T11:49:55.918739Z",
     "shell.execute_reply": "2024-07-21T11:49:55.917914Z"
    },
    "papermill": {
     "duration": 0.012209,
     "end_time": "2024-07-21T11:49:55.920709",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.908500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# model = AutoEncoder()\n",
    "# model2=SimNet()\n",
    "\n",
    "# dummy_input_x = torch.randn(1, 1, 300, 300)  # Example input shape (batch_size, channels, height, width)\n",
    "# dummy_input_y = torch.randn(1, 1, 300, 300)  # Example input shape (batch_size, channels, height, width)\n",
    "# output = model(dummy_input_x,dummy_input_y)\n",
    "# out=model2(output[2],output[3])\n",
    "# print(output[0].shape,output[1].shape,output[2].shape,output[3].shape)\n",
    "\n",
    "# # print(\"Output shape:\", output.shape)  # Check the final output shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a284fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.931921Z",
     "iopub.status.busy": "2024-07-21T11:49:55.931594Z",
     "iopub.status.idle": "2024-07-21T11:49:55.935463Z",
     "shell.execute_reply": "2024-07-21T11:49:55.934632Z"
    },
    "papermill": {
     "duration": 0.011864,
     "end_time": "2024-07-21T11:49:55.937550",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.925686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ceffecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.948713Z",
     "iopub.status.busy": "2024-07-21T11:49:55.948200Z",
     "iopub.status.idle": "2024-07-21T11:49:55.955974Z",
     "shell.execute_reply": "2024-07-21T11:49:55.955071Z"
    },
    "papermill": {
     "duration": 0.015514,
     "end_time": "2024-07-21T11:49:55.958046",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.942532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining loss function \n",
    "# it is a combination of reconstructive loss of the autoencoder and classification loss for the image pair\n",
    "class RanaKaGhata(torch.nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, beta=1.0,lambda_l2=1e-5):\n",
    "        super(RanaKaGhata, self).__init__() \n",
    "        self.beta=beta\n",
    "        self.lambda_l2=lambda_l2\n",
    "        \n",
    "\n",
    "    def forward(self,x_orig,y_orig,x_predict,y_predict,sim,label,model_1,model_2):\n",
    "        base_loss=self.beta*(F.l1_loss(x_orig,x_predict)+F.l1_loss(y_orig,y_predict))+F.binary_cross_entropy(sim,label)\n",
    "        l2_loss=0\n",
    "        for param in model_1.parameters():\n",
    "            l2_loss += torch.sum(param.pow(2))\n",
    "        for param in model_2.parameters():\n",
    "            l2_loss += torch.sum(param.pow(2))\n",
    "        total_loss=base_loss+self.lambda_l2*l2_loss\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67173d48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.969513Z",
     "iopub.status.busy": "2024-07-21T11:49:55.969232Z",
     "iopub.status.idle": "2024-07-21T11:49:55.977370Z",
     "shell.execute_reply": "2024-07-21T11:49:55.976518Z"
    },
    "papermill": {
     "duration": 0.016195,
     "end_time": "2024-07-21T11:49:55.979339",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.963144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to check the accuracy of the model\n",
    "def check_accuracy(model_1,model_2,dataloader,batch_size=128,datasplit=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net_1=model_1\n",
    "    net_2=model_2\n",
    "\n",
    "    net_1.eval()\n",
    "    net_1.eval()\n",
    "    count=0\n",
    "    correct=0\n",
    "    incorrect=0\n",
    "    for i, data in enumerate(dataloader,0): \n",
    "      \n",
    "  \n",
    "      x, y , label = data\n",
    "      label=label.to(device)\n",
    "  \n",
    "\n",
    "      output_x,output_y,encoding_x,encoding_y = model_1(x.to(device),y.to(device))\n",
    "      prob_forged=model_2(encoding_x,encoding_y)\n",
    "      predicted_label=prob_forged>0.5\n",
    "      predicted_label=predicted_label.to(device)\n",
    "      correct_prediction=torch.sum(predicted_label==label)\n",
    "      correct+=correct_prediction\n",
    "      incorrect+=(batch_size-correct_prediction)\n",
    "    if datasplit is not None:\n",
    "        print(f\"the accuracy on {datasplit} data is {(correct)/(correct+incorrect)} \")\n",
    "    else:\n",
    "         print(f\"the accuracy  is {(correct)/(correct+incorrect)} \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f64d711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T11:49:55.991296Z",
     "iopub.status.busy": "2024-07-21T11:49:55.990593Z",
     "iopub.status.idle": "2024-07-21T12:42:11.175101Z",
     "shell.execute_reply": "2024-07-21T12:42:11.174095Z"
    },
    "papermill": {
     "duration": 3135.192747,
     "end_time": "2024-07-21T12:42:11.177234",
     "exception": false,
     "start_time": "2024-07-21T11:49:55.984487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/2682337449.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sample = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))# for Randomly picking a signature\n",
      "/tmp/ipykernel_24/2682337449.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(np.random.randint(low = 0 , high = 2 , size = 1)) # selecting the second image.\n",
      "/tmp/ipykernel_24/2682337449.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sample1 = str(int(np.random.randint(low = 1 , high = 31 , size = 1)))\n",
      "/tmp/ipykernel_24/2682337449.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sample2 = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8573825359344482\n",
      "0.7837045788764954\n",
      "0.7697741389274597\n",
      "0.7694457173347473\n",
      "0.7666014432907104\n",
      "Epoch 1\n",
      " Current loss 0.7893816828727722\n",
      "\n",
      "0.7687183618545532\n",
      "0.7580142021179199\n",
      "0.7506350874900818\n",
      "0.7503160834312439\n",
      "0.7762767672538757\n",
      "Epoch 2\n",
      " Current loss 0.7607921004295349\n",
      "\n",
      "0.7233070135116577\n",
      "0.7332537174224854\n",
      "0.7442395091056824\n",
      "0.7367328405380249\n",
      "0.717529833316803\n",
      "Epoch 3\n",
      " Current loss 0.7310125827789307\n",
      "\n",
      "0.7612476348876953\n",
      "0.7332717180252075\n",
      "0.6911291480064392\n",
      "0.7507902979850769\n",
      "0.7562478184700012\n",
      "Epoch 4\n",
      " Current loss 0.738537323474884\n",
      "\n",
      "0.6920214891433716\n",
      "0.666950523853302\n",
      "0.7099829316139221\n",
      "0.691887378692627\n",
      "0.7053150534629822\n",
      "Epoch 5\n",
      " Current loss 0.6932314753532409\n",
      "\n",
      "the accuracy on test data is 0.66796875 \n",
      "0.7177795767784119\n",
      "0.6779161095619202\n",
      "0.6241999864578247\n",
      "0.5600513815879822\n",
      "0.6291500926017761\n",
      "Epoch 6\n",
      " Current loss 0.641819429397583\n",
      "\n",
      "0.5855602025985718\n",
      "0.6574175357818604\n",
      "0.5366244912147522\n",
      "0.6844483613967896\n",
      "0.5960546135902405\n",
      "Epoch 7\n",
      " Current loss 0.6120210409164428\n",
      "\n",
      "0.5458934307098389\n",
      "0.622868001461029\n",
      "0.5879555344581604\n",
      "0.5234386324882507\n",
      "0.5582470893859863\n",
      "Epoch 8\n",
      " Current loss 0.5676805377006531\n",
      "\n",
      "0.5703335404396057\n",
      "0.49676692485809326\n",
      "0.5491319298744202\n",
      "0.5939540863037109\n",
      "0.5453793406486511\n",
      "Epoch 9\n",
      " Current loss 0.5511131644248962\n",
      "\n",
      "0.45274442434310913\n",
      "0.5756754279136658\n",
      "0.52690190076828\n",
      "0.5883990526199341\n",
      "0.5040322542190552\n",
      "Epoch 10\n",
      " Current loss 0.5295506119728088\n",
      "\n",
      "the accuracy on test data is 0.6966145634651184 \n",
      "0.6212280988693237\n",
      "0.5666818618774414\n",
      "0.47756651043891907\n",
      "0.5029151439666748\n",
      "0.5073382258415222\n",
      "Epoch 11\n",
      " Current loss 0.5351459681987762\n",
      "\n",
      "0.4641375243663788\n",
      "0.5174432396888733\n",
      "0.55281001329422\n",
      "0.5527780652046204\n",
      "0.4948105812072754\n",
      "Epoch 12\n",
      " Current loss 0.5163958847522736\n",
      "\n",
      "0.5349826216697693\n",
      "0.5468822121620178\n",
      "0.5269975662231445\n",
      "0.5008525252342224\n",
      "0.5374888777732849\n",
      "Epoch 13\n",
      " Current loss 0.5294407606124878\n",
      "\n",
      "0.5711230635643005\n",
      "0.5099284648895264\n",
      "0.5363224744796753\n",
      "0.6565467715263367\n",
      "0.566902756690979\n",
      "Epoch 14\n",
      " Current loss 0.5681647062301636\n",
      "\n",
      "0.5624505281448364\n",
      "0.5105901956558228\n",
      "0.5394964814186096\n",
      "0.578961193561554\n",
      "0.4768810272216797\n",
      "Epoch 15\n",
      " Current loss 0.5336758852005005\n",
      "\n",
      "the accuracy on test data is 0.7513020634651184 \n",
      "0.4671507179737091\n",
      "0.597213864326477\n",
      "0.530814528465271\n",
      "0.5470778346061707\n",
      "0.6191280484199524\n",
      "Epoch 16\n",
      " Current loss 0.552276998758316\n",
      "\n",
      "0.5243198275566101\n",
      "0.5138854384422302\n",
      "0.5939052700996399\n",
      "0.45996540784835815\n",
      "0.4868640601634979\n",
      "Epoch 17\n",
      " Current loss 0.5157880008220672\n",
      "\n",
      "0.5377124547958374\n",
      "0.606699526309967\n",
      "0.5406590700149536\n",
      "0.4399986267089844\n",
      "0.49013668298721313\n",
      "Epoch 18\n",
      " Current loss 0.5230412721633911\n",
      "\n",
      "0.48961973190307617\n",
      "0.4937930405139923\n",
      "0.575762927532196\n",
      "0.5339604020118713\n",
      "0.5642192363739014\n",
      "Epoch 19\n",
      " Current loss 0.5314710676670075\n",
      "\n",
      "0.4673081338405609\n",
      "0.5577369332313538\n",
      "0.5838277339935303\n",
      "0.44491684436798096\n",
      "0.501227080821991\n",
      "Epoch 20\n",
      " Current loss 0.5110033452510834\n",
      "\n",
      "the accuracy on test data is 0.7760416865348816 \n",
      "0.42138367891311646\n",
      "0.4654257893562317\n",
      "0.45619145035743713\n",
      "0.39141491055488586\n",
      "0.42390966415405273\n",
      "Epoch 21\n",
      " Current loss 0.43166509866714475\n",
      "\n",
      "0.5083466172218323\n",
      "0.5460426211357117\n",
      "0.4294201731681824\n",
      "0.3908179700374603\n",
      "0.47198420763015747\n",
      "Epoch 22\n",
      " Current loss 0.46932231783866885\n",
      "\n",
      "0.4182780086994171\n",
      "0.4504278302192688\n",
      "0.4672187864780426\n",
      "0.4528604745864868\n",
      "0.4657834768295288\n",
      "Epoch 23\n",
      " Current loss 0.4509137153625488\n",
      "\n",
      "0.46129393577575684\n",
      "0.4024762809276581\n",
      "0.44937342405319214\n",
      "0.46412813663482666\n",
      "0.4177955090999603\n",
      "Epoch 24\n",
      " Current loss 0.4390134572982788\n",
      "\n",
      "0.4195098280906677\n",
      "0.44524678587913513\n",
      "0.45639896392822266\n",
      "0.5061945915222168\n",
      "0.36615443229675293\n",
      "Epoch 25\n",
      " Current loss 0.438700920343399\n",
      "\n",
      "the accuracy on test data is 0.7916666865348816 \n",
      "0.3791547417640686\n",
      "0.4886527359485626\n",
      "0.48881545662879944\n",
      "0.4795999228954315\n",
      "0.5015490651130676\n",
      "Epoch 26\n",
      " Current loss 0.467554384469986\n",
      "\n",
      "0.4473913013935089\n",
      "0.46658191084861755\n",
      "0.5116142630577087\n",
      "0.49816563725471497\n",
      "0.4435317814350128\n",
      "Epoch 27\n",
      " Current loss 0.4734569787979126\n",
      "\n",
      "0.40692567825317383\n",
      "0.38322746753692627\n",
      "0.4043779969215393\n",
      "0.4049433469772339\n",
      "0.5526403784751892\n",
      "Epoch 28\n",
      " Current loss 0.4304229736328125\n",
      "\n",
      "0.4883975088596344\n",
      "0.366472989320755\n",
      "0.5643243789672852\n",
      "0.5125131607055664\n",
      "0.35712122917175293\n",
      "Epoch 29\n",
      " Current loss 0.45776585340499876\n",
      "\n",
      "0.48176196217536926\n",
      "0.33703500032424927\n",
      "0.41642892360687256\n",
      "0.46927595138549805\n",
      "0.42052650451660156\n",
      "Epoch 30\n",
      " Current loss 0.42500566840171816\n",
      "\n",
      "the accuracy on test data is 0.77734375 \n",
      "0.341866135597229\n",
      "0.3971461355686188\n",
      "0.43641918897628784\n",
      "0.4427814185619354\n",
      "0.3383903205394745\n",
      "Epoch 31\n",
      " Current loss 0.39132063984870913\n",
      "\n",
      "0.42034807801246643\n",
      "0.3545225262641907\n",
      "0.4168187379837036\n",
      "0.48257941007614136\n",
      "0.3107980787754059\n",
      "Epoch 32\n",
      " Current loss 0.3970133662223816\n",
      "\n",
      "0.5056028366088867\n",
      "0.40656259655952454\n",
      "0.43466588854789734\n",
      "0.3710837662220001\n",
      "0.3920808732509613\n",
      "Epoch 33\n",
      " Current loss 0.421999192237854\n",
      "\n",
      "0.4094874858856201\n",
      "0.39978787302970886\n",
      "0.404031902551651\n",
      "0.3830583691596985\n",
      "0.43979132175445557\n",
      "Epoch 34\n",
      " Current loss 0.4072313904762268\n",
      "\n",
      "0.41702166199684143\n",
      "0.3788301348686218\n",
      "0.38960784673690796\n",
      "0.4024341404438019\n",
      "0.3675788938999176\n",
      "Epoch 35\n",
      " Current loss 0.39109453558921814\n",
      "\n",
      "the accuracy on test data is 0.78515625 \n",
      "0.33154237270355225\n",
      "0.409231573343277\n",
      "0.38090816140174866\n",
      "0.37081602215766907\n",
      "0.5287793874740601\n",
      "Epoch 36\n",
      " Current loss 0.4042555034160614\n",
      "\n",
      "0.3188021779060364\n",
      "0.42808210849761963\n",
      "0.32590994238853455\n",
      "0.3915371298789978\n",
      "0.2994413673877716\n",
      "Epoch 37\n",
      " Current loss 0.352754545211792\n",
      "\n",
      "0.3402535617351532\n",
      "0.36432766914367676\n",
      "0.3318215608596802\n",
      "0.32928529381752014\n",
      "0.37888044118881226\n",
      "Epoch 38\n",
      " Current loss 0.3489137053489685\n",
      "\n",
      "0.3491215109825134\n",
      "0.2970468997955322\n",
      "0.37252700328826904\n",
      "0.3097594380378723\n",
      "0.38544145226478577\n",
      "Epoch 39\n",
      " Current loss 0.34277926087379457\n",
      "\n",
      "0.30472531914711\n",
      "0.3307836651802063\n",
      "0.4418390691280365\n",
      "0.372251033782959\n",
      "0.40898597240448\n",
      "Epoch 40\n",
      " Current loss 0.3717170119285583\n",
      "\n",
      "the accuracy on test data is 0.82421875 \n",
      "0.37272918224334717\n",
      "0.2913575768470764\n",
      "0.2821824848651886\n",
      "0.32649293541908264\n",
      "0.3230620324611664\n",
      "Epoch 41\n",
      " Current loss 0.31916484236717224\n",
      "\n",
      "0.321092814207077\n",
      "0.36198264360427856\n",
      "0.280995637178421\n",
      "0.3882828652858734\n",
      "0.3845258951187134\n",
      "Epoch 42\n",
      " Current loss 0.3473759710788727\n",
      "\n",
      "0.3979105055332184\n",
      "0.3162148892879486\n",
      "0.30396032333374023\n",
      "0.31289780139923096\n",
      "0.3245513141155243\n",
      "Epoch 43\n",
      " Current loss 0.3311069667339325\n",
      "\n",
      "0.3395534157752991\n",
      "0.33003750443458557\n",
      "0.26737815141677856\n",
      "0.3739559054374695\n",
      "0.37680548429489136\n",
      "Epoch 44\n",
      " Current loss 0.3375460922718048\n",
      "\n",
      "0.370131254196167\n",
      "0.3460851013660431\n",
      "0.32881593704223633\n",
      "0.24151788651943207\n",
      "0.27367088198661804\n",
      "Epoch 45\n",
      " Current loss 0.3120442122220993\n",
      "\n",
      "the accuracy on test data is 0.8203125 \n",
      "0.314300537109375\n",
      "0.24646593630313873\n",
      "0.4097580015659332\n",
      "0.24107125401496887\n",
      "0.3248162567615509\n",
      "Epoch 46\n",
      " Current loss 0.30728239715099337\n",
      "\n",
      "0.27703535556793213\n",
      "0.33661264181137085\n",
      "0.2777559757232666\n",
      "0.29444244503974915\n",
      "0.2908555865287781\n",
      "Epoch 47\n",
      " Current loss 0.29534040093421937\n",
      "\n",
      "0.4474891424179077\n",
      "0.2557419240474701\n",
      "0.28395721316337585\n",
      "0.3062397241592407\n",
      "0.3496267795562744\n",
      "Epoch 48\n",
      " Current loss 0.32861095666885376\n",
      "\n",
      "0.2523038685321808\n",
      "0.26104608178138733\n",
      "0.2909099757671356\n",
      "0.28816959261894226\n",
      "0.25652003288269043\n",
      "Epoch 49\n",
      " Current loss 0.26978991031646726\n",
      "\n",
      "0.32955050468444824\n",
      "0.3450179398059845\n",
      "0.22427718341350555\n",
      "0.2264721393585205\n",
      "0.2682778835296631\n",
      "Epoch 50\n",
      " Current loss 0.27871913015842437\n",
      "\n",
      "the accuracy on test data is 0.8203125 \n",
      "0.2966652810573578\n",
      "0.24791470170021057\n",
      "0.2509174048900604\n",
      "0.26860755681991577\n",
      "0.28328797221183777\n",
      "Epoch 51\n",
      " Current loss 0.2694785833358765\n",
      "\n",
      "0.28791940212249756\n",
      "0.24196231365203857\n",
      "0.19917908310890198\n",
      "0.2623330056667328\n",
      "0.29306110739707947\n",
      "Epoch 52\n",
      " Current loss 0.2568909823894501\n",
      "\n",
      "0.2067149430513382\n",
      "0.2254946380853653\n",
      "0.28865450620651245\n",
      "0.25430577993392944\n",
      "0.21837309002876282\n",
      "Epoch 53\n",
      " Current loss 0.23870859146118165\n",
      "\n",
      "0.267609566450119\n",
      "0.20888257026672363\n",
      "0.26329198479652405\n",
      "0.2719797194004059\n",
      "0.2583949863910675\n",
      "Epoch 54\n",
      " Current loss 0.254031765460968\n",
      "\n",
      "0.22915267944335938\n",
      "0.3062109649181366\n",
      "0.23064279556274414\n",
      "0.2621457278728485\n",
      "0.19951030611991882\n",
      "Epoch 55\n",
      " Current loss 0.2455324947834015\n",
      "\n",
      "the accuracy on test data is 0.796875 \n",
      "0.2282179743051529\n",
      "0.17532193660736084\n",
      "0.2397211492061615\n",
      "0.2604605555534363\n",
      "0.16553857922554016\n",
      "Epoch 56\n",
      " Current loss 0.21385203897953034\n",
      "\n",
      "0.25268712639808655\n",
      "0.22394192218780518\n",
      "0.2691895663738251\n",
      "0.2694874405860901\n",
      "0.20964932441711426\n",
      "Epoch 57\n",
      " Current loss 0.24499107599258424\n",
      "\n",
      "0.2095748633146286\n",
      "0.20368990302085876\n",
      "0.18557463586330414\n",
      "0.19645161926746368\n",
      "0.18610736727714539\n",
      "Epoch 58\n",
      " Current loss 0.1962796777486801\n",
      "\n",
      "0.20951613783836365\n",
      "0.2171829491853714\n",
      "0.24118788540363312\n",
      "0.22301602363586426\n",
      "0.2033425271511078\n",
      "Epoch 59\n",
      " Current loss 0.21884910464286805\n",
      "\n",
      "0.19167211651802063\n",
      "0.18050645291805267\n",
      "0.22530801594257355\n",
      "0.22046254575252533\n",
      "0.14998038113117218\n",
      "Epoch 60\n",
      " Current loss 0.19358590245246887\n",
      "\n",
      "the accuracy on test data is 0.82421875 \n",
      "0.20350611209869385\n",
      "0.23240044713020325\n",
      "0.19206874072551727\n",
      "0.21414433419704437\n",
      "0.17316481471061707\n",
      "Epoch 61\n",
      " Current loss 0.20305688977241515\n",
      "\n",
      "0.17455224692821503\n",
      "0.17918364703655243\n",
      "0.1865658164024353\n",
      "0.1820715069770813\n",
      "0.2718801200389862\n",
      "Epoch 62\n",
      " Current loss 0.19885066747665406\n",
      "\n",
      "0.3000040352344513\n",
      "0.19546322524547577\n",
      "0.22362104058265686\n",
      "0.18438775837421417\n",
      "0.19101186096668243\n",
      "Epoch 63\n",
      " Current loss 0.2188975840806961\n",
      "\n",
      "0.17937526106834412\n",
      "0.21978166699409485\n",
      "0.18699701130390167\n",
      "0.21024568378925323\n",
      "0.1941870152950287\n",
      "Epoch 64\n",
      " Current loss 0.19811732769012452\n",
      "\n",
      "0.15306295454502106\n",
      "0.17871180176734924\n",
      "0.21401125192642212\n",
      "0.23306681215763092\n",
      "0.17923854291439056\n",
      "Epoch 65\n",
      " Current loss 0.19161827266216278\n",
      "\n",
      "the accuracy on test data is 0.7955729365348816 \n",
      "0.13984675705432892\n",
      "0.20775620639324188\n",
      "0.13256776332855225\n",
      "0.17511805891990662\n",
      "0.20025292038917542\n",
      "Epoch 66\n",
      " Current loss 0.17110834121704102\n",
      "\n",
      "0.13720053434371948\n",
      "0.1360262930393219\n",
      "0.19019187986850739\n",
      "0.1537393033504486\n",
      "0.18366199731826782\n",
      "Epoch 67\n",
      " Current loss 0.16016400158405303\n",
      "\n",
      "0.23250149190425873\n",
      "0.17930278182029724\n",
      "0.18878760933876038\n",
      "0.15051379799842834\n",
      "0.14373911917209625\n",
      "Epoch 68\n",
      " Current loss 0.17896896004676818\n",
      "\n",
      "0.21862336993217468\n",
      "0.23533344268798828\n",
      "0.19324862957000732\n",
      "0.17411907017230988\n",
      "0.17943115532398224\n",
      "Epoch 69\n",
      " Current loss 0.20015113353729247\n",
      "\n",
      "0.1300077885389328\n",
      "0.1769181191921234\n",
      "0.1976531594991684\n",
      "0.16733872890472412\n",
      "0.16727156937122345\n",
      "Epoch 70\n",
      " Current loss 0.16783787310123444\n",
      "\n",
      "the accuracy on test data is 0.7877604365348816 \n",
      "0.1477869600057602\n",
      "0.16037365794181824\n",
      "0.14096419513225555\n",
      "0.14932328462600708\n",
      "0.17637012898921967\n",
      "Epoch 71\n",
      " Current loss 0.15496364533901213\n",
      "\n",
      "0.15720966458320618\n",
      "0.16173626482486725\n",
      "0.14779484272003174\n",
      "0.1851494461297989\n",
      "0.16046127676963806\n",
      "Epoch 72\n",
      " Current loss 0.1624702990055084\n",
      "\n",
      "0.20370960235595703\n",
      "0.1717042475938797\n",
      "0.11089274287223816\n",
      "0.1903010606765747\n",
      "0.17572158575057983\n",
      "Epoch 73\n",
      " Current loss 0.1704658478498459\n",
      "\n",
      "0.17711326479911804\n",
      "0.15625321865081787\n",
      "0.14869540929794312\n",
      "0.2539438009262085\n",
      "0.1131056398153305\n",
      "Epoch 74\n",
      " Current loss 0.1698222666978836\n",
      "\n",
      "0.13869786262512207\n",
      "0.16270136833190918\n",
      "0.1203918531537056\n",
      "0.21703103184700012\n",
      "0.17711226642131805\n",
      "Epoch 75\n",
      " Current loss 0.163186876475811\n",
      "\n",
      "the accuracy on test data is 0.7825520634651184 \n",
      "0.1413297951221466\n",
      "0.15048298239707947\n",
      "0.14538118243217468\n",
      "0.12241727858781815\n",
      "0.11836433410644531\n",
      "Epoch 76\n",
      " Current loss 0.13559511452913284\n",
      "\n",
      "0.20499880611896515\n",
      "0.13103832304477692\n",
      "0.10584238171577454\n",
      "0.12201563268899918\n",
      "0.1164790689945221\n",
      "Epoch 77\n",
      " Current loss 0.13607484251260757\n",
      "\n",
      "0.15728875994682312\n",
      "0.14578036963939667\n",
      "0.19151121377944946\n",
      "0.15954139828681946\n",
      "0.17449797689914703\n",
      "Epoch 78\n",
      " Current loss 0.16572394371032714\n",
      "\n",
      "0.15813732147216797\n",
      "0.1290075033903122\n",
      "0.13043172657489777\n",
      "0.1359683722257614\n",
      "0.12115316838026047\n",
      "Epoch 79\n",
      " Current loss 0.13493961840867996\n",
      "\n",
      "0.1403702348470688\n",
      "0.13084954023361206\n",
      "0.10213466733694077\n",
      "0.1172817051410675\n",
      "0.12345544248819351\n",
      "Epoch 80\n",
      " Current loss 0.12281831800937652\n",
      "\n",
      "the accuracy on test data is 0.7942708134651184 \n",
      "0.10199873894453049\n",
      "0.09256644546985626\n",
      "0.15206943452358246\n",
      "0.1355823278427124\n",
      "0.12059102207422256\n",
      "Epoch 81\n",
      " Current loss 0.12056159377098083\n",
      "\n",
      "0.1255023181438446\n",
      "0.13657259941101074\n",
      "0.11234698444604874\n",
      "0.10476167500019073\n",
      "0.10490013659000397\n",
      "Epoch 82\n",
      " Current loss 0.11681674271821976\n",
      "\n",
      "0.10553423315286636\n",
      "0.116111621260643\n",
      "0.12519685924053192\n",
      "0.10051112622022629\n",
      "0.12042488902807236\n",
      "Epoch 83\n",
      " Current loss 0.11355574578046798\n",
      "\n",
      "0.16542312502861023\n",
      "0.1160031259059906\n",
      "0.10733228921890259\n",
      "0.11296668648719788\n",
      "0.09586717188358307\n",
      "Epoch 84\n",
      " Current loss 0.11951847970485688\n",
      "\n",
      "0.13935387134552002\n",
      "0.1380424052476883\n",
      "0.13594956696033478\n",
      "0.127200186252594\n",
      "0.10591737926006317\n",
      "Epoch 85\n",
      " Current loss 0.12929268181324005\n",
      "\n",
      "the accuracy on test data is 0.7955729365348816 \n",
      "0.10385429114103317\n",
      "0.11612756550312042\n",
      "0.10214050859212875\n",
      "0.09624955803155899\n",
      "0.12428565323352814\n",
      "Epoch 86\n",
      " Current loss 0.1085315153002739\n",
      "\n",
      "0.09819716215133667\n",
      "0.11364579200744629\n",
      "0.10968350619077682\n",
      "0.10553532093763351\n",
      "0.12403257191181183\n",
      "Epoch 87\n",
      " Current loss 0.11021887063980103\n",
      "\n",
      "0.09863973408937454\n",
      "0.09869490563869476\n",
      "0.1106405258178711\n",
      "0.09329117834568024\n",
      "0.10370229184627533\n",
      "Epoch 88\n",
      " Current loss 0.10099372714757919\n",
      "\n",
      "0.10389372706413269\n",
      "0.12033237516880035\n",
      "0.10721933841705322\n",
      "0.09631744027137756\n",
      "0.0969286635518074\n",
      "Epoch 89\n",
      " Current loss 0.10493830889463425\n",
      "\n",
      "0.11445911228656769\n",
      "0.1106179729104042\n",
      "0.10701938718557358\n",
      "0.11610908061265945\n",
      "0.11099081486463547\n",
      "Epoch 90\n",
      " Current loss 0.11183927357196807\n",
      "\n",
      "the accuracy on test data is 0.8020833134651184 \n",
      "0.09190371632575989\n",
      "0.11131715029478073\n",
      "0.09071647375822067\n",
      "0.107319675385952\n",
      "0.09936052560806274\n",
      "Epoch 91\n",
      " Current loss 0.10012350827455521\n",
      "\n",
      "0.0867173820734024\n",
      "0.10338837653398514\n",
      "0.09388918429613113\n",
      "0.10033115744590759\n",
      "0.11736665666103363\n",
      "Epoch 92\n",
      " Current loss 0.10033855140209198\n",
      "\n",
      "0.09882313758134842\n",
      "0.20324085652828217\n",
      "0.12288353592157364\n",
      "0.08481917530298233\n",
      "0.10852662473917007\n",
      "Epoch 93\n",
      " Current loss 0.12365866601467132\n",
      "\n",
      "0.10786942392587662\n",
      "0.09023860841989517\n",
      "0.08727864921092987\n",
      "0.0913994163274765\n",
      "0.12485484033823013\n",
      "Epoch 94\n",
      " Current loss 0.10032818764448166\n",
      "\n",
      "0.14000354707241058\n",
      "0.09737113863229752\n",
      "0.10327543318271637\n",
      "0.09720385819673538\n",
      "0.08982297033071518\n",
      "Epoch 95\n",
      " Current loss 0.105535389482975\n",
      "\n",
      "the accuracy on test data is 0.796875 \n",
      "0.10304614901542664\n",
      "0.08629133552312851\n",
      "0.09977582097053528\n",
      "0.10832585394382477\n",
      "0.11431803554296494\n",
      "Epoch 96\n",
      " Current loss 0.10235143899917602\n",
      "\n",
      "0.12128741294145584\n",
      "0.11019116640090942\n",
      "0.0968191996216774\n",
      "0.09910288453102112\n",
      "0.08995101600885391\n",
      "Epoch 97\n",
      " Current loss 0.10347033590078354\n",
      "\n",
      "0.0870976597070694\n",
      "0.0923929437994957\n",
      "0.11137867718935013\n",
      "0.12148597091436386\n",
      "0.11178556084632874\n",
      "Epoch 98\n",
      " Current loss 0.10482816249132157\n",
      "\n",
      "0.10919206589460373\n",
      "0.08010676503181458\n",
      "0.09694921225309372\n",
      "0.09154896438121796\n",
      "0.09754272550344467\n",
      "Epoch 99\n",
      " Current loss 0.09506794661283494\n",
      "\n",
      "0.10462715476751328\n",
      "0.13820095360279083\n",
      "0.10803061723709106\n",
      "0.11790059506893158\n",
      "0.11157216876745224\n",
      "Epoch 100\n",
      " Current loss 0.1160662978887558\n",
      "\n",
      "the accuracy on test data is 0.8489583134651184 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "#loading training data\n",
    "\n",
    "train_dataset=SigDataset_train(r\"/kaggle/input/bhsig260-hindi/BHSig260-Hindi\",\n",
    "                               transforms=transforms.Compose([transforms.Resize((300,300)),transforms.ToTensor()]))\n",
    "\n",
    "train_dataloader=DataLoader(train_dataset,shuffle=True,batch_size=64,drop_last=True)\n",
    "#loading testing data\n",
    "test_dataset=SigDataset_test(r\"/kaggle/input/bhsig260-hindi/BHSig260-Hindi\",\n",
    "                               transforms=transforms.Compose([transforms.Resize((300,300)),transforms.ToTensor()]))\n",
    "test_dataloader=DataLoader(test_dataset,shuffle=True,batch_size=32,drop_last=True)\n",
    "# Declaring Auto-Siamese Network\n",
    "net_1= AutoEncoder().cuda()\n",
    "net_2=SimNet().cuda()\n",
    "net_1.train()\n",
    "net_2.train()\n",
    "# Decalre Loss Function\n",
    "criterion = RanaKaGhata()\n",
    "# Declare Optimizer\n",
    "optimizer_1 = torch.optim.Adam(net_1.parameters(), lr=1e-3)\n",
    "optimizer_2 = torch.optim.Adam(net_2.parameters(), lr=1e-4 )\n",
    "# setup learning rate scheduler\n",
    "scheduler_1=CosineAnnealingLR(optimizer_1,T_max=45)\n",
    "scheduler_2=CosineAnnealingLR(optimizer_2,T_max=45)\n",
    "\n",
    "#defining the traing loop\n",
    "def train(epochs=100):\n",
    "    loss=[] #stores the average loss for each epoch\n",
    "    counter=[]#created for loss plot\n",
    "    iteration_number = 0\n",
    "    for epoch in range(1,epochs+1):\n",
    "        loss_temp=[]\n",
    "        for i, data in enumerate(train_dataloader,0):\n",
    "            img0, img1 , label = data\n",
    "            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "            optimizer_1.zero_grad()\n",
    "            optimizer_2.zero_grad()\n",
    "            output_x,output_y,encoding_x,encoding_y = net_1(img0,img1)\n",
    "            sim=net_2(encoding_x,encoding_y)\n",
    "            loss_test = criterion(img0,img1,output_x,output_y,sim,label,net_1,net_2)\n",
    "            \n",
    "            if (i%10)==0:\n",
    "                print(loss_test.item())#prints loss every 10 batches\n",
    "                loss_temp.append(loss_test.item())#used for average loss computation during an epoch\n",
    "                \n",
    "            loss_test.backward()\n",
    "            optimizer_1.step()   \n",
    "            optimizer_2.step()   \n",
    "            scheduler_1.step()\n",
    "            scheduler_2.step()\n",
    "            \n",
    "        print(\"Epoch {}\\n Current loss {}\\n\".format(epoch,np.mean(loss_temp)))#prints average loss during the epoch\n",
    "        iteration_number += 10\n",
    "        counter.append(iteration_number)\n",
    "        \n",
    "        loss.append(np.mean(loss_temp))\n",
    "        if epoch%5==0:#after every 5 epochs checks the model performance on the test dataset\n",
    "            # helps to determine when does the model starts to overfit\n",
    "                check_accuracy(net_1,net_2,test_dataloader,batch_size=32,datasplit='test')\n",
    "\n",
    "    plt.plot(counter, loss)   \n",
    "    plt.show()\n",
    "    return net_1,net_2\n",
    "\n",
    "\n",
    "#set the device to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_1,model_2 = train()\n",
    "# saves the model\n",
    "torch.save(model_1.state_dict(), \"auto_siamese-model_1_state_dicts.pt\")\n",
    "torch.save(model_2.state_dict(), \"auto_siamese-model_2_state_dicts.pt\")\n",
    "print(\"Models Saved Successfully\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde012f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T12:42:11.283682Z",
     "iopub.status.busy": "2024-07-21T12:42:11.283312Z",
     "iopub.status.idle": "2024-07-21T12:42:40.492435Z",
     "shell.execute_reply": "2024-07-21T12:42:40.491426Z"
    },
    "papermill": {
     "duration": 29.264833,
     "end_time": "2024-07-21T12:42:40.494373",
     "exception": false,
     "start_time": "2024-07-21T12:42:11.229540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/2682337449.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sample = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))# for Randomly picking a signature\n",
      "/tmp/ipykernel_24/2682337449.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(np.random.randint(low = 0 , high = 2 , size = 1)) # selecting the second image.\n",
      "/tmp/ipykernel_24/2682337449.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sample2 = str(int(np.random.randint(low = 1 , high = 25 , size = 1)))\n",
      "/tmp/ipykernel_24/2682337449.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sample1 = str(int(np.random.randint(low = 1 , high = 31 , size = 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on train data is 0.994140625 \n"
     ]
    }
   ],
   "source": [
    "# check the models performance on training data\n",
    "check_accuracy(model_1,model_2,train_dataloader,batch_size=64,datasplit='train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60ab74d",
   "metadata": {
    "papermill": {
     "duration": 0.051728,
     "end_time": "2024-07-21T12:42:40.599333",
     "exception": false,
     "start_time": "2024-07-21T12:42:40.547605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f1fcb",
   "metadata": {
    "papermill": {
     "duration": 0.052137,
     "end_time": "2024-07-21T12:42:40.703761",
     "exception": false,
     "start_time": "2024-07-21T12:42:40.651624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18507a",
   "metadata": {
    "papermill": {
     "duration": 0.051863,
     "end_time": "2024-07-21T12:42:40.807565",
     "exception": false,
     "start_time": "2024-07-21T12:42:40.755702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1512017,
     "sourceId": 2497231,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5390138,
     "sourceId": 8956243,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5393385,
     "sourceId": 8960715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5393520,
     "sourceId": 8960892,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5393588,
     "sourceId": 8960998,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3175.301384,
   "end_time": "2024-07-21T12:42:42.388404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-21T11:49:47.087020",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
